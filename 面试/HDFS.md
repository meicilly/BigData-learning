### HDFS文件的写流程(简略版)
1. 客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已经存在，父目录是否存在。
2. NameNode返回是否可以上传。
3. 客户端请求第一个block上传到哪几个datanode服务器上。
4. NameNode返回3个datanode节点，分别为dn1、dn2、dn3。
5. 客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。
6. dn1,dn2,dn3逐级但应客户。
7. 客户端开始往dn1上传第一个block(先从磁盘读取数据放到一个本地内存缓存)，以packet为单位，dn1收到一个packet就会传给dn2,dn2传给dn3;dn1每传一个packet会放入一个应答队列等待应答。
8. 当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。
![hdfs写数据流程图](./img/01_HDFS写数据过程.png)
### HDFS读数据流程(简略版)
1. 客户端向NameNode请求读文件，NameNode通过查询元数据，找到文件块所在的DataNode地址，并返回地址给客户端。
2. 挑选一台DataNode(就近原则，然后随机)服务器，请求读取数据
3. DataNode开始传输数据给客户端（从磁盘里面读取数据入流，以packet为单位校验）
4. 客户端以packet为单位接收，先在本地缓存，然后写入目标文件
5. 关闭资源

### HDFS的容错机制
#### 故障检测机制
1. 针对DataNode失效问题
每个DataNode以固定的周期向NameNode发送心跳信号，通过这种方法告诉NameNode它们在正常工作。如果在一定的时间内NameNode没有收到DataNode心跳，就任务该DataNode宕机了。
2. 针对网络故障而导致无法收发数据
HDFS提供ACK的机制，在发送端发送数据后，如果没有手动ACK并且经过多次重试后仍然如此，则认为网络故障。
3. 针对数损坏(脏数据)问题
- 在传输数据的时候，同时会发送总和校验码，当数据存储到硬盘时，总和校验码也会被存储
- 所有DataNode都会定期向NameNode发送数据块的存储情况
- 在发送数据块报告前，会先检查总和校验码是否正确，如果数据存在错误就不发送该数据块的信息
### HDFS的常见数据格式，列式存储格式和行存储格式异同点，列式存储优点有哪些
- Hadoop中的文件格式大致上分为面向行和面向列两类
1. 行式存储
一条数据保存为一行，读取一行中的任何值都需要把整行数据读取出来(如：Sequence Files,MapFile,Avro Data Files),这种方式在磁盘读取的开销比较大，这无法避免。
2. 列式存储
整个文件被切割为若干列数据，每一列中数据保存在一起(如：Parquet,RC Files,ORC Files,Carbon Data,IndexR)。这种方式会占用更多的内存空间，需要将行数据缓存起来。
- 列存储和行存储优缺点
```
行存储
优点：行存储的写入是一次性完成的，写入效率高，消耗时间比列存储少，并且能够保证数据的完整性
缺点：数据读取过程中会产生冗余数据，如果只少看数据，此影响可以忽略；数量大可能会影响数据的处理效率。
```
```
列存储
优点：在读取过程中，不会产生冗余数据，这对数据完整性要求不高的大数据处理领域尤为重要
缺点：写入效率，保证数据完整性上都不如行存储
```
### HDFS如何保证数据不丢失
1. 数据在写入之后进行校验和的计算，DataNode周期性的进行校验和计算，将计算结果与第一次进行对比，若同时表示无数据丢失，若不相同表示数据丢失，丢失后进行数据修复。
2. 数据读取之前对数据进行校验，与第一次的结果进行对比，若相同表示数据没有丢失，可以读取，若不相同表示数据有所丢失，到其他副本读物数据。
#### 保证DataNode节点保证数据完整性的方法
1. 当DataNode读取Block的时候，会计算CheckSum